{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc90806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import warnings\n",
    "\n",
    "def set_chinese_font():\n",
    "    \"\"\"\n",
    "    è‡ªåŠ¨æŸ¥æ‰¾å¹¶è®¾ç½®æ”¯æŒä¸­æ–‡çš„å­—ä½“ï¼Œé¿å…Glyph missingè­¦å‘Š\n",
    "    \"\"\"\n",
    "    # å¸¸è§çš„ä¸­æ–‡å­—ä½“åç§°åˆ—è¡¨\n",
    "    chinese_fonts = [\n",
    "        'SimHei', 'SimSun', 'Microsoft YaHei', 'STHeiti', \n",
    "        'Songti SC', 'PingFang SC', 'Noto Sans CJK SC',\n",
    "        'AR PL UKai CN', 'Noto Sans Kaithi', 'WenQuanYi Micro Hei'\n",
    "    ]\n",
    "    \n",
    "    available_fonts = set([f.name for f in fm.fontManager.ttflist])\n",
    "    \n",
    "    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“\n",
    "    selected_font = None\n",
    "    for font in chinese_fonts:\n",
    "        if font in available_fonts:\n",
    "            selected_font = font\n",
    "            break\n",
    "    \n",
    "    # å¦‚æœæ‰¾ä¸åˆ°é¢„å®šä¹‰çš„å­—ä½“ï¼Œåˆ™ä½¿ç”¨ç³»ç»Ÿä¸­çš„ä»»æ„å­—ä½“\n",
    "    if not selected_font:\n",
    "        # æŸ¥æ‰¾ä»»ä½•åŒ…å«ä¸­æ–‡å­—ç¬¦çš„å­—ä½“\n",
    "        for font in available_fonts:\n",
    "            if any(chinese_char in font for chinese_char in ['é»‘', 'å®‹', 'æ¥·', 'ä»¿', 'è‹¹', 'å¾®']):\n",
    "                selected_font = font\n",
    "                break\n",
    "    \n",
    "    # è®¾ç½®å­—ä½“\n",
    "    if selected_font:\n",
    "        plt.rcParams['font.sans-serif'] = [selected_font, 'DejaVu Sans']\n",
    "        print(f\"å·²è®¾ç½®ä¸­æ–‡å­—ä½“: {selected_font}\")\n",
    "    else:\n",
    "        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨é»˜è®¤å­—ä½“ä½†ç¡®ä¿èƒ½æ˜¾ç¤ºåŸºæœ¬ä¸­æ–‡\n",
    "        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'sans-serif']\n",
    "        print(\"æœªæ‰¾åˆ°åˆé€‚çš„ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“\")\n",
    "        \n",
    "    # ç¡®ä¿è´Ÿå·æ­£å¸¸æ˜¾ç¤º\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    return selected_font\n",
    "\n",
    "# åº”ç”¨å­—ä½“è®¾ç½®\n",
    "set_chinese_font()\n",
    "\n",
    "# æµ‹è¯•å­—ä½“æ˜¯å¦æ­£å¸¸å·¥ä½œ\n",
    "def test_chinese_display():\n",
    "    \"\"\"\n",
    "    æµ‹è¯•ä¸­æ–‡æ˜¾ç¤ºåŠŸèƒ½\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.text(0.5, 0.5, 'æµ‹è¯•ä¸­æ–‡æ˜¾ç¤ºï¼šé»„é‡‘ çŸ­è é•¿å€º è‚¡ç¥¨', \n",
    "                fontsize=14, ha='center', va='center')\n",
    "        plt.title('å­—ä½“æµ‹è¯•å›¾è¡¨')\n",
    "        plt.show()\n",
    "        print(\"ä¸­æ–‡æ˜¾ç¤ºæµ‹è¯•æˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"ä¸­æ–‡æ˜¾ç¤ºæµ‹è¯•å¤±è´¥: {e}\")\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "test_chinese_display()\n",
    "plt.rcParams['axes.unicode_minus'] = False  # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fund_data_by_date(*dataframes):\n",
    "    merged_df = dataframes[0][['date', 'price']].copy()\n",
    "    merged_df.columns = ['date', 'price_0']\n",
    "    for i, df in enumerate(dataframes[1:], 1):\n",
    "        temp_df = df[['date', 'price']].copy()\n",
    "        temp_df.columns = ['date', f'price_{i}']\n",
    "        merged_df = merged_df.merge(temp_df, on='date', how='inner')\n",
    "    price_columns = [col for col in merged_df.columns if col.startswith('price_')]\n",
    "    merged_df['price'] = merged_df[price_columns].sum(axis=1)/len(price_columns)\n",
    "    return merged_df[['date', 'price']]\n",
    "\n",
    "def quit_zero(stock):\n",
    "    stock_zero_mask = stock['price'] == 0\n",
    "    zero_indices = stock[stock_zero_mask].index\n",
    "    for idx in zero_indices:\n",
    "        # æŸ¥æ‰¾å‰ä¸€ä¸ªéé›¶å€¼\n",
    "        prev_idx = idx - 1\n",
    "        while prev_idx >= 0 and stock.loc[prev_idx, 'price'] == 0:\n",
    "            prev_idx -= 1\n",
    "        \n",
    "        # æŸ¥æ‰¾åä¸€ä¸ªéé›¶å€¼\n",
    "        next_idx = idx + 1\n",
    "        while next_idx < len(stock) and stock.loc[next_idx, 'price'] == 0:\n",
    "            next_idx += 1\n",
    "        \n",
    "        # è®¡ç®—å‰åéé›¶å€¼çš„å¹³å‡å€¼\n",
    "        prev_value = stock.loc[prev_idx, 'price'] if prev_idx >= 0 else 0\n",
    "        next_value = stock.loc[next_idx, 'price'] if next_idx < len(stock) else prev_value\n",
    "        \n",
    "        # å¦‚æœå‰å€¼ä¸º0ä½†åå€¼ä¸ä¸º0ï¼Œåˆ™ä½¿ç”¨åå€¼\n",
    "        if prev_value == 0 and next_value != 0:\n",
    "            stock.loc[idx, 'price'] = next_value\n",
    "        # å¦‚æœåå€¼ä¸º0ä½†å‰å€¼ä¸ä¸º0ï¼Œåˆ™ä½¿ç”¨å‰å€¼\n",
    "        elif next_value == 0 and prev_value != 0:\n",
    "            stock.loc[idx, 'price'] = prev_value\n",
    "        # å¦‚æœå‰åå€¼éƒ½ä¸ä¸º0ï¼Œåˆ™å–å¹³å‡å€¼\n",
    "        elif prev_value != 0 and next_value != 0:\n",
    "            stock.loc[idx, 'price'] = (prev_value + next_value) / 2\n",
    "        # å¦‚æœéƒ½ä¸º0ï¼Œåˆ™ä¿æŒåŸå€¼ï¼ˆè¿™ç§æƒ…å†µå¾ˆå°‘è§ï¼‰\n",
    "\n",
    "# é»„é‡‘ 000218\n",
    "# çŸ­è 000128, 008448\n",
    "# é•¿å€º  003376\n",
    "# 30é•¿å€º 010309\n",
    "# ç¾å€º 004998\n",
    "# çº¢åˆ© 161907, 510880, 009051\n",
    "# çº¢åˆ©ä½æ³¢ 005561, 512890, 021482\n",
    "# æ ‡æ™® 161125\n",
    "# çº³æ–¯è¾¾å…‹ 160213\n",
    "# åˆ›ä¸šæ¿ 110026\n",
    "# ä¸Šè¯50 001051\n",
    "# æ²ªæ·±300 460300\n",
    "def get_data():\n",
    "    d1 = ak.fund_open_fund_info_em(symbol=\"000218\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    cash = ak.fund_open_fund_info_em(symbol=\"000128\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'}) #çŸ­èç°é‡‘å‚¨å¤‡ä¸èƒ½æ”¹\n",
    "    d2 = ak.fund_open_fund_info_em(symbol=\"010309\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    #è‚¡ç¥¨\n",
    "    d3 = ak.fund_open_fund_info_em(symbol=\"510880\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    d4 = ak.fund_open_fund_info_em(symbol=\"512890\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    stock = merge_fund_data_by_date(d3, d4)\n",
    "    # d3 = ak.fund_open_fund_info_em(symbol=\"110026\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    # d4 = ak.fund_open_fund_info_em(symbol=\"001051\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    # d5 = ak.fund_open_fund_info_em(symbol=\"460300\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    # stock = merge_fund_data_by_date(d3, d4, d5)\n",
    "    # d6 = ak.fund_open_fund_info_em(symbol=\"512890\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "    # stock = merge_fund_data_by_date(d3, d4, d5, d6)\n",
    "    quit_zero(stock)\n",
    "    dataframes = [d1, cash, d2, stock]\n",
    "    merged_data = reduce(lambda left, right: left.merge(right, on='date', how='inner', suffixes=('', '_right')), dataframes)\n",
    "    merged_data.columns = ['date', 'é»„é‡‘', 'çŸ­è', 'é•¿å€º', 'è‚¡ç¥¨']\n",
    "    merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
    "    return merged_data\n",
    "\n",
    "# def get_data():\n",
    "#     d1 = ak.fund_open_fund_info_em(symbol=\"000218\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "#     cash = ak.fund_open_fund_info_em(symbol=\"000128\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'}) #çŸ­èç°é‡‘å‚¨å¤‡ä¸èƒ½æ”¹\n",
    "#     d2 = ak.fund_open_fund_info_em(symbol=\"003376\", indicator=\"ç´¯è®¡å‡€å€¼èµ°åŠ¿\").rename(columns={'å‡€å€¼æ—¥æœŸ': 'date', 'ç´¯è®¡å‡€å€¼': 'price'})\n",
    "#     d7 = pd.read_csv('./btc_daily_nav_2016_to_now.csv')\n",
    "#     d7['date'] = pd.to_datetime(d7['date']).dt.date\n",
    "#     d1['date'] = pd.to_datetime(d1['date']).dt.date\n",
    "#     cash['date'] = pd.to_datetime(cash['date']).dt.date\n",
    "#     d2['date'] = pd.to_datetime(d2['date']).dt.date\n",
    "#     dataframes = [d1, cash, d2, d7]\n",
    "#     merged_data = reduce(lambda left, right: left.merge(right, on='date', how='inner', suffixes=('', '_right')), dataframes)\n",
    "#     merged_data.columns = ['date', 'é»„é‡‘', 'çŸ­è', 'é•¿å€º', 'è‚¡ç¥¨']\n",
    "#     # å¦‚æœéœ€è¦ï¼Œå¯ä»¥å°†æ—¥æœŸåˆ—è½¬æ¢å›datetimeç±»å‹\n",
    "#     merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
    "#     return merged_data\n",
    "merged_data = get_data()\n",
    "start_year = 2018\n",
    "start_month = 4\n",
    "first_date = merged_data['date'].iloc[0]\n",
    "if first_date.month == 12:\n",
    "    start_year = first_date.year + 1\n",
    "    start_month = 1\n",
    "else:\n",
    "    start_year = first_date.year\n",
    "    start_month = first_date.month + 1\n",
    "end_year = datetime.now().year\n",
    "end_month = datetime.now().month\n",
    "print(merged_data)\n",
    "# merged_data[['é»„é‡‘', 'çŸ­è', 'é•¿å€º', 'è‚¡ç¥¨']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_risk(current_price, see_months=3, invest_amount=10000):\n",
    "    merged_data = get_data()\n",
    "    recent_data = merged_data.tail(see_months*20).copy()\n",
    "    etf_columns = ['é»„é‡‘', 'é•¿å€º', 'è‚¡ç¥¨']\n",
    "    for col in etf_columns:\n",
    "        recent_data.loc[:, f'{col}_pct'] = recent_data.loc[:, col].pct_change(fill_method=None) * 100\n",
    "\n",
    "    pct_columns = ['é»„é‡‘_pct', 'é•¿å€º_pct', 'è‚¡ç¥¨_pct']\n",
    "    etf_data = recent_data.loc[:, pct_columns]\n",
    "    daily_returns = etf_data.dropna()\n",
    "    volatility = daily_returns.std() * np.sqrt(252)\n",
    "    print(f\"å„ç±»èµ„äº§{see_months}ä¸ªæœˆå¹´åŒ–æ³¢åŠ¨ç‡ï¼š\")\n",
    "    print(volatility.round(4), \"\\n\")\n",
    "    current_weights = current_price / current_price.sum()\n",
    "    current_weights = pd.Series(current_weights, index=pct_columns)\n",
    "\n",
    "    # é£é™©è´¡çŒ® = ä»“ä½æƒé‡ Ã— èµ„äº§æ³¢åŠ¨ç‡\n",
    "    risk_contribution = current_weights * volatility\n",
    "    total_risk = risk_contribution.sum()\n",
    "\n",
    "    # é£é™©è´¡çŒ®å æ¯”ï¼ˆå½“å‰é£é™©æ¯”ä¾‹ï¼‰\n",
    "    risk_ratio = (risk_contribution / total_risk).round(4) * 100\n",
    "    print(\"å½“å‰ä»“ä½çš„é£é™©è´¡çŒ®å æ¯”ï¼š\")\n",
    "    print(risk_ratio, \"\\n\")\n",
    "\n",
    "    target_risk_ratio = 1/3  # 33.33%\n",
    "\n",
    "    # åŠ ä»“ç³»æ•° = ç›®æ ‡é£é™©å æ¯” / å½“å‰é£é™©å æ¯”ï¼ˆé£é™©è¶Šé«˜ï¼Œç³»æ•°è¶Šå°ï¼ŒåŠ ä»“è¶Šå°‘ï¼‰\n",
    "    add_coefficient = target_risk_ratio / (risk_ratio / 100)\n",
    "    print(\"å®šæŠ•åŠ ä»“ç³»æ•°ï¼š\")\n",
    "    print(add_coefficient.round(4), \"\\n\")\n",
    "\n",
    "    # åˆ†é…åŠ ä»“é‡‘é¢ï¼ˆå‡è®¾å½“æœˆå®šæŠ•1ä¸‡å…ƒï¼‰\n",
    "    add_weights = add_coefficient / add_coefficient.sum()  # åŠ ä»“æ¯”ä¾‹\n",
    "    add_amount = (add_weights * invest_amount).round(0)\n",
    "\n",
    "    print(f\"{invest_amount}å…ƒå®šæŠ•çš„åŠ ä»“é‡‘é¢åˆ†é…ï¼š\")\n",
    "    result = pd.DataFrame({\n",
    "        'å½“å‰ä»“ä½æƒé‡': current_weights * 100,\n",
    "        'å½“å‰é£é™©å æ¯”(%)': risk_ratio,\n",
    "        'åŠ ä»“ç³»æ•°': add_coefficient.round(4),\n",
    "        'å®šæŠ•é‡‘é¢(å…ƒ)': add_amount\n",
    "    })\n",
    "    print(result)\n",
    "\n",
    "equal_risk(np.array([1, 1, 1]), 3, 158000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_etf_monthly_data(year, month):\n",
    "    \"\"\"\n",
    "    åˆ†ææŒ‡å®šå¹´æœˆçš„ETFæ•°æ®å¹¶è®¡ç®—é£é™©æ¯”ä¾‹å’Œç›¸å…³ç³»æ•°\n",
    "    \n",
    "    Parameters:\n",
    "    year (int): å¹´ä»½\n",
    "    month (int): æœˆä»½\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (risk_contribution, correlation_matrix)\n",
    "    \"\"\"\n",
    "    merged_data = get_data()\n",
    "    \n",
    "    mask = (merged_data['date'].dt.year == year) & (merged_data['date'].dt.month == month)\n",
    "    monthly_data = merged_data.loc[mask].copy() \n",
    "    \n",
    "    if monthly_data.empty:\n",
    "        print(f\"è­¦å‘Š: {year}å¹´{month}æœˆæ²¡æœ‰æ‰¾åˆ°æ•°æ®\")\n",
    "        return None, None\n",
    "    \n",
    "    etf_columns = ['é»„é‡‘', 'çŸ­è', 'é•¿å€º', 'è‚¡ç¥¨']\n",
    "    for col in etf_columns:\n",
    "        monthly_data.loc[:, f'{col}_pct'] = monthly_data.loc[:, col].pct_change(fill_method=None) * 100\n",
    "    \n",
    "    pct_columns = ['é»„é‡‘_pct', 'çŸ­è_pct', 'é•¿å€º_pct', 'è‚¡ç¥¨_pct']\n",
    "    etf_data = monthly_data.loc[:, pct_columns]\n",
    "    etf_data = etf_data.dropna()\n",
    "    \n",
    "    if etf_data.empty:\n",
    "        print(f\"è­¦å‘Š: {year}å¹´{month}æœˆæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡\")\n",
    "        return None, None\n",
    "    \n",
    "    volatility = etf_data.std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡\n",
    "    total_volatility = volatility.sum()\n",
    "    risk_contribution = volatility / total_volatility * 100\n",
    "    \n",
    "    return risk_contribution, etf_data.corr()\n",
    "\n",
    "def get_etf_analysis_period(start_year, start_month, end_year, end_month):\n",
    "    \"\"\"\n",
    "    è·å–æŒ‡å®šæ—¶é—´æ®µå†…æ¯æœˆçš„ETFé£é™©æ¯”ä¾‹å’Œç›¸å…³ç³»æ•°çŸ©é˜µ\n",
    "    \n",
    "    Parameters:\n",
    "    start_year (int): å¼€å§‹å¹´ä»½\n",
    "    start_month (int): å¼€å§‹æœˆä»½\n",
    "    end_year (int): ç»“æŸå¹´ä»½\n",
    "    end_month (int): ç»“æŸæœˆä»½\n",
    "    \n",
    "    Returns:\n",
    "    dict: åŒ…å«æ¯æœˆé£é™©æ¯”ä¾‹å’Œç›¸å…³ç³»æ•°çŸ©é˜µçš„å­—å…¸\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    current_year = start_year\n",
    "    current_month = start_month\n",
    "    \n",
    "    while (current_year < end_year) or (current_year == end_year and current_month <= end_month):\n",
    "        try:\n",
    "            risk_ratio, corr_matrix = analyze_etf_monthly_data(current_year, current_month)\n",
    "            if risk_ratio is not None and corr_matrix is not None:\n",
    "                results[f\"{current_year}-{current_month:02d}\"] = {\n",
    "                    'risk_ratio': risk_ratio,\n",
    "                    'corr_matrix': corr_matrix\n",
    "                }\n",
    "            else:\n",
    "                print(f\"{current_year}å¹´{current_month:02d}æœˆ æ•°æ®ä¸è¶³æˆ–ä¸å­˜åœ¨\")\n",
    "        except Exception as e:\n",
    "            print(f\"å¤„ç† {current_year}å¹´{current_month:02d}æœˆ æ•°æ®æ—¶å‡ºé”™: {e}\")\n",
    "        current_month += 1\n",
    "        if current_month > 12:\n",
    "            current_month = 1\n",
    "            current_year += 1\n",
    "    return results\n",
    "\n",
    "def print_summary_statistics(results):\n",
    "    \"\"\"\n",
    "    æ‰“å°æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"æ²¡æœ‰æ•°æ®å¯ä¾›ç»Ÿè®¡\")\n",
    "        return\n",
    "    \n",
    "    dates = sorted(list(results.keys()))\n",
    "    etf_names = list(results[list(results.keys())[0]]['risk_ratio'].index)\n",
    "    \n",
    "    periods = {\n",
    "        \"è¿‘1ä¸ªæœˆ\": 1,\n",
    "        \"è¿‘3ä¸ªæœˆ\": 3,\n",
    "        \"è¿‘åŠå¹´\": 6,\n",
    "        \"è¿‘1å¹´\": 12,\n",
    "        \"è¿‘3å¹´\": 36,\n",
    "        \"ä»æœ€æ—©åˆ°ç›®å‰ä¸ºæ­¢\": len(dates)\n",
    "    }\n",
    "    \n",
    "    for period_name, months in periods.items():\n",
    "        if months >= len(dates):\n",
    "            period_dates = dates \n",
    "        else:\n",
    "            start_index = max(0, len(dates) - months)\n",
    "            period_dates = dates[start_index:]\n",
    "        \n",
    "        if not period_dates:\n",
    "            print(f\"\\n{period_name}: æ²¡æœ‰æ•°æ®\")\n",
    "            continue\n",
    "            \n",
    "        avg_risk_data = {}\n",
    "        for etf in etf_names:\n",
    "            avg_risk_data[etf] = sum([results[date]['risk_ratio'][etf] for date in period_dates]) / len(period_dates)\n",
    "        \n",
    "        print(f\"\\n{period_name} ({period_dates[0]} åˆ° {period_dates[-1]}):\")\n",
    "        print(\"  å¹³å‡é£é™©æ¯”ä¾‹:\")\n",
    "        for etf, ratio in avg_risk_data.items():\n",
    "            print(f\"    {etf}: {ratio:.4f}\")\n",
    "        \n",
    "        if months <= 6:\n",
    "            continue\n",
    "        median_risk_data = {}\n",
    "        for etf in etf_names:\n",
    "            risk_values = [results[date]['risk_ratio'][etf] for date in period_dates]\n",
    "            risk_values.sort()\n",
    "            n = len(risk_values)\n",
    "            if n % 2 == 0:\n",
    "                median_risk_data[etf] = (risk_values[n//2 - 1] + risk_values[n//2]) / 2\n",
    "            else:\n",
    "                median_risk_data[etf] = risk_values[n//2]\n",
    "        \n",
    "        print(\"  ä¸­ä½æ•°é£é™©æ¯”ä¾‹:\")\n",
    "        for etf, ratio in median_risk_data.items():\n",
    "            print(f\"    {etf}: {ratio:.4f}\")\n",
    "        \n",
    "def visualize_risk_ratios(results):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–é£é™©æ¯”ä¾‹å˜åŒ–è¶‹åŠ¿\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"æ²¡æœ‰æ•°æ®å¯ä¾›å¯è§†åŒ–\")\n",
    "        return\n",
    "    \n",
    "    # å‡†å¤‡æ•°æ®\n",
    "    dates = list(results.keys())\n",
    "    etf_names = list(results[list(results.keys())[0]]['risk_ratio'].index)\n",
    "    \n",
    "    # åˆ›å»ºDataFrameå­˜å‚¨é£é™©æ¯”ä¾‹æ•°æ®\n",
    "    risk_data = {}\n",
    "    for etf in etf_names:\n",
    "        risk_data[etf] = [results[date]['risk_ratio'][etf] for date in dates]\n",
    "    \n",
    "    risk_df = pd.DataFrame(risk_data, index=dates)\n",
    "    \n",
    "    # ç»˜åˆ¶é£é™©æ¯”ä¾‹å˜åŒ–å›¾\n",
    "    plt.figure(figsize=(24, 8))\n",
    "    for etf in etf_names:\n",
    "        plt.plot(risk_df.index, risk_df[etf], marker='o', label=etf, linewidth=2)\n",
    "    \n",
    "    plt.title('å„ETFé£é™©æ¯”ä¾‹æœˆåº¦å˜åŒ–è¶‹åŠ¿', fontsize=16)\n",
    "    plt.xlabel('æœˆä»½', fontsize=12)\n",
    "    plt.ylabel('é£é™©æ¯”ä¾‹', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=65)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_portfolio_drawdown_and_recovery(merged_data, weights):\n",
    "    \"\"\"\n",
    "    è®¡ç®—ç»™å®šæƒé‡çš„æŠ•èµ„ç»„åˆçš„æœ€å¤§å›æ’¤å’Œå›æ’¤ä¿®å¤æ—¶é—´\n",
    "    \n",
    "    Parameters:\n",
    "    merged_data (DataFrame): åŒ…å«å„èµ„äº§å‡€å€¼æ•°æ®çš„DataFrame\n",
    "    weights (dict): å„èµ„äº§çš„æƒé‡é…ç½®\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (æœ€å¤§å›æ’¤, å›æ’¤å¼€å§‹æ—¥æœŸ, å›æ’¤ç»“æŸæ—¥æœŸ, ä¿®å¤æ—¥æœŸ, ä¿®å¤æœˆæ•°)\n",
    "    \"\"\"\n",
    "    # è®¡ç®—ç»„åˆå‡€å€¼\n",
    "    portfolio_value = pd.Series(0, index=merged_data.index)\n",
    "    \n",
    "    # å½’ä¸€åŒ–åˆå§‹ä»·æ ¼ï¼Œä½¿æ‰€æœ‰èµ„äº§èµ·å§‹å€¼ä¸º1\n",
    "    for asset in weights.keys():\n",
    "        normalized_prices = merged_data[asset] / merged_data[asset].iloc[0]\n",
    "        portfolio_value += normalized_prices * weights[asset]\n",
    "    \n",
    "    # åˆ›å»ºç»„åˆæ•°æ®DataFrame\n",
    "    portfolio_df = pd.DataFrame({\n",
    "        'date': merged_data['date'],\n",
    "        'value': portfolio_value\n",
    "    })\n",
    "    \n",
    "    # æŒ‰æ—¥æœŸæ’åº\n",
    "    portfolio_df = portfolio_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # è®¡ç®—ç´¯ç§¯å‡€å€¼åºåˆ—çš„å³°å€¼\n",
    "    portfolio_df['peak'] = portfolio_df['value'].expanding(min_periods=1).max()\n",
    "    \n",
    "    # è®¡ç®—å›æ’¤\n",
    "    portfolio_df['drawdown'] = (portfolio_df['value'] - portfolio_df['peak']) / portfolio_df['peak']\n",
    "    \n",
    "    # æ‰¾åˆ°æœ€å¤§å›æ’¤çš„ä½ç½®\n",
    "    max_drawdown_idx = portfolio_df['drawdown'].idxmin()\n",
    "    max_drawdown = portfolio_df.loc[max_drawdown_idx, 'drawdown']\n",
    "    \n",
    "    # è·å–æœ€å¤§å›æ’¤çš„æ—¥æœŸä¿¡æ¯\n",
    "    max_drawdown_date = portfolio_df.loc[max_drawdown_idx, 'date']\n",
    "    \n",
    "    # æ‰¾åˆ°å›æ’¤å¼€å§‹å‰çš„å³°å€¼æ—¥æœŸ\n",
    "    peak_value = portfolio_df.loc[max_drawdown_idx, 'peak']\n",
    "    # peak_idx = portfolio_df[portfolio_df['date'] <= max_drawdown_date][portfolio_df['value'] == peak_value].index[-1]\n",
    "    mask = (portfolio_df['date'] <= max_drawdown_date) & (portfolio_df['value'] == peak_value)\n",
    "    peak_idx = portfolio_df[mask].index[-1]\n",
    "    peak_date = portfolio_df.loc[peak_idx, 'date']\n",
    "    \n",
    "    # è®¡ç®—ä¿®å¤æ—¶é—´\n",
    "    recovery_idx = None\n",
    "    recovery_date = None\n",
    "    recovery_months = None\n",
    "    \n",
    "    # å¯»æ‰¾å›æ’¤ä¿®å¤æ—¥æœŸï¼ˆå‡€å€¼é‡æ–°è¾¾åˆ°å³°å€¼ï¼‰\n",
    "    for idx in range(max_drawdown_idx + 1, len(portfolio_df)):\n",
    "        if portfolio_df.loc[idx, 'value'] >= peak_value:\n",
    "            recovery_idx = idx\n",
    "            recovery_date = portfolio_df.loc[idx, 'date']\n",
    "            # è®¡ç®—æœˆä»½æ•°\n",
    "            months = (recovery_date.year - peak_date.year) * 12 + (recovery_date.month - peak_date.month)\n",
    "            recovery_months = months\n",
    "            break\n",
    "    \n",
    "    return max_drawdown, peak_date, max_drawdown_date, recovery_date, recovery_months\n",
    "\n",
    "def calculate_max_drawdown_and_recovery(data, asset_column):\n",
    "    \"\"\"\n",
    "    è®¡ç®—æœ€å¤§å›æ’¤å’Œå›æ’¤ä¿®å¤æ—¶é—´\n",
    "    \n",
    "    Parameters:\n",
    "    data (DataFrame): åŒ…å«æ—¥æœŸå’Œèµ„äº§å‡€å€¼çš„æ•°æ®\n",
    "    asset_column (str): èµ„äº§åˆ—å\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (æœ€å¤§å›æ’¤, å›æ’¤å¼€å§‹æ—¥æœŸ, å›æ’¤ç»“æŸæ—¥æœŸ, ä¿®å¤æ—¥æœŸ, ä¿®å¤æœˆæ•°)\n",
    "    \"\"\"\n",
    "    # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº\n",
    "    df = data[['date', asset_column]].copy()\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # è®¡ç®—ç´¯ç§¯å‡€å€¼åºåˆ—çš„å³°å€¼\n",
    "    df['peak'] = df[asset_column].expanding(min_periods=1).max()\n",
    "    \n",
    "    # è®¡ç®—å›æ’¤\n",
    "    df['drawdown'] = (df[asset_column] - df['peak']) / df['peak']\n",
    "    \n",
    "    # æ‰¾åˆ°æœ€å¤§å›æ’¤çš„ä½ç½®\n",
    "    max_drawdown_idx = df['drawdown'].idxmin()\n",
    "    max_drawdown = df.loc[max_drawdown_idx, 'drawdown']\n",
    "    \n",
    "    # è·å–æœ€å¤§å›æ’¤çš„æ—¥æœŸä¿¡æ¯\n",
    "    max_drawdown_date = df.loc[max_drawdown_idx, 'date']\n",
    "    \n",
    "    # æ‰¾åˆ°å›æ’¤å¼€å§‹å‰çš„å³°å€¼æ—¥æœŸ\n",
    "    peak_value = df.loc[max_drawdown_idx, 'peak']\n",
    "    mask = (df['date'] <= max_drawdown_date) & (df[asset_column] == peak_value)\n",
    "    peak_idx = df[mask].index[-1]\n",
    "    peak_date = df.loc[peak_idx, 'date']\n",
    "    \n",
    "    # è®¡ç®—ä¿®å¤æ—¶é—´\n",
    "    recovery_idx = None\n",
    "    recovery_date = None\n",
    "    recovery_months = None\n",
    "    \n",
    "    # å¯»æ‰¾å›æ’¤ä¿®å¤æ—¥æœŸï¼ˆå‡€å€¼é‡æ–°è¾¾åˆ°å³°å€¼ï¼‰\n",
    "    for idx in range(max_drawdown_idx + 1, len(df)):\n",
    "        if df.loc[idx, asset_column] >= peak_value:\n",
    "            recovery_idx = idx\n",
    "            recovery_date = df.loc[idx, 'date']\n",
    "            # è®¡ç®—æœˆä»½æ•°\n",
    "            months = (recovery_date.year - peak_date.year) * 12 + (recovery_date.month - peak_date.month)\n",
    "            recovery_months = months\n",
    "            break\n",
    "    \n",
    "    return max_drawdown, peak_date, max_drawdown_date, recovery_date, recovery_months\n",
    "\n",
    "\n",
    "# ç»˜åˆ¶ç»„åˆå›æ’¤æ›²çº¿å›¾\n",
    "def plot_portfolio_drawdown(merged_data, weights):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶æŠ•èµ„ç»„åˆçš„å›æ’¤æ›²çº¿\n",
    "    \"\"\"\n",
    "    # è®¡ç®—ç»„åˆå‡€å€¼\n",
    "    portfolio_value = pd.Series(0, index=merged_data.index)\n",
    "    \n",
    "    # å½’ä¸€åŒ–åˆå§‹ä»·æ ¼ï¼Œä½¿æ‰€æœ‰èµ„äº§èµ·å§‹å€¼ä¸º1\n",
    "    for asset in weights.keys():\n",
    "        normalized_prices = merged_data[asset] / merged_data[asset].iloc[0]\n",
    "        portfolio_value += normalized_prices * weights[asset]\n",
    "    \n",
    "    # åˆ›å»ºç»„åˆæ•°æ®DataFrame\n",
    "    portfolio_df = pd.DataFrame({\n",
    "        'date': merged_data['date'],\n",
    "        'value': portfolio_value\n",
    "    })\n",
    "    \n",
    "    # æŒ‰æ—¥æœŸæ’åº\n",
    "    portfolio_df = portfolio_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # è®¡ç®—ç´¯ç§¯å‡€å€¼åºåˆ—çš„å³°å€¼å’Œå›æ’¤\n",
    "    portfolio_df['peak'] = portfolio_df['value'].expanding(min_periods=1).max()\n",
    "    portfolio_df['drawdown'] = (portfolio_df['value'] - portfolio_df['peak']) / portfolio_df['peak']\n",
    "    \n",
    "    # ç»˜åˆ¶å›¾å½¢\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # å­å›¾1: ç»„åˆå‡€å€¼èµ°åŠ¿\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(portfolio_df['date'], portfolio_df['value'], color='purple', linewidth=2, label='ç»„åˆå‡€å€¼')\n",
    "    plt.plot(portfolio_df['date'], portfolio_df['peak'], color='green', linestyle='--', linewidth=1, label='å†å²å³°å€¼')\n",
    "    plt.title('æŠ•èµ„ç»„åˆå‡€å€¼èµ°åŠ¿', fontsize=14)\n",
    "    plt.ylabel('å‡€å€¼')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ ‡æ³¨æœ€å¤§å›æ’¤ç‚¹\n",
    "    max_dd_idx = portfolio_df['drawdown'].idxmin()\n",
    "    max_dd_value = portfolio_df.loc[max_dd_idx, 'drawdown']\n",
    "    max_dd_date = portfolio_df.loc[max_dd_idx, 'date']\n",
    "    max_dd_nav = portfolio_df.loc[max_dd_idx, 'value']\n",
    "    peak_value = portfolio_df.loc[max_dd_idx, 'peak']\n",
    "    \n",
    "    plt.scatter(max_dd_date, max_dd_nav, color='red', s=80, zorder=5)\n",
    "    plt.annotate(f'æœ€å¤§å›æ’¤ç‚¹\\n{max_dd_value*100:.2f}%', \n",
    "                xy=(max_dd_date, max_dd_nav), \n",
    "                xytext=(20, 20), \n",
    "                textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    # å­å›¾2: å›æ’¤æ›²çº¿\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(portfolio_df['date'], portfolio_df['drawdown'], color='red', linewidth=2)\n",
    "    plt.fill_between(portfolio_df['date'], portfolio_df['drawdown'], 0, color='red', alpha=0.3)\n",
    "    plt.title('æŠ•èµ„ç»„åˆå›æ’¤æ›²çº¿', fontsize=14)\n",
    "    plt.ylabel('å›æ’¤ (%)')\n",
    "    plt.xlabel('æ—¥æœŸ')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ ‡æ³¨æœ€å¤§å›æ’¤ç‚¹\n",
    "    plt.scatter(max_dd_date, max_dd_value, color='darkred', s=80, zorder=5)\n",
    "    plt.annotate(f'æœ€å¤§å›æ’¤\\n{max_dd_value*100:.2f}%', \n",
    "                xy=(max_dd_date, max_dd_value), \n",
    "                xytext=(20, -20), \n",
    "                textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return portfolio_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2343, 2)\n",
      "(1191, 2)\n",
      "(4616, 2)\n",
      "(1671, 2)\n",
      "(2343, 2)\n",
      "(1191, 2)\n",
      "(4616, 2)\n",
      "(1671, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"å¼€å§‹åˆ†æ{start_year}å¹´{start_month}æœˆè‡³{end_year}å¹´{end_month}æœˆçš„ETFæ•°æ®...\")\n",
    "results = get_etf_analysis_period(start_year, start_month, end_year, end_month)\n",
    "print_summary_statistics(results)\n",
    "visualize_risk_ratios(results)\n",
    "# å®šä¹‰èµ„äº§æƒé‡\n",
    "portfolio_weights = {\n",
    "    'çŸ­è': 0.25,\n",
    "    'é•¿å€º': 0.25,\n",
    "    'é»„é‡‘': 0.25,\n",
    "    'è‚¡ç¥¨': 0.25,\n",
    "}\n",
    "\n",
    "# è®¡ç®—ç»„åˆæœ€å¤§å›æ’¤å’Œä¿®å¤æ—¶é—´\n",
    "try:\n",
    "    max_dd, peak_date, dd_date, recovery_date, recovery_months = calculate_portfolio_drawdown_and_recovery(\n",
    "        merged_data, portfolio_weights\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"æŒ‡å®šæƒé‡ç»„åˆçš„æœ€å¤§å›æ’¤åŠä¿®å¤æ—¶é—´åˆ†æ\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"ç»„åˆæƒé‡é…ç½®:\")\n",
    "    for asset, weight in portfolio_weights.items():\n",
    "        print(f\"  {asset}: {weight*100:.1f}%\")\n",
    "    print()\n",
    "    print(\"åˆ†æç»“æœ:\")\n",
    "    print(f\"  æœ€å¤§å›æ’¤: {max_dd*100:.2f}%\")\n",
    "    print(f\"  å›æ’¤å¼€å§‹æ—¥æœŸ(å³°å€¼): {peak_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  æœ€å¤§å›æ’¤æ—¥æœŸ: {dd_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    if recovery_date:\n",
    "        print(f\"  å›æ’¤ä¿®å¤æ—¥æœŸ: {recovery_date.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  ä¿®å¤æ—¶é—´: {recovery_months} ä¸ªæœˆ\")\n",
    "    else:\n",
    "        print(\"  å›æ’¤ä¿®å¤æ—¥æœŸ: å°šæœªä¿®å¤\")\n",
    "        # è®¡ç®—è‡³ä»Šçš„ä¿®å¤æ—¶é—´\n",
    "        last_date = merged_data['date'].max()\n",
    "        months_since_peak = (last_date.year - peak_date.year) * 12 + (last_date.month - peak_date.month)\n",
    "        print(f\"  è‡³ä»Šä¿®å¤æ—¶é—´: {months_since_peak} ä¸ªæœˆ (å°šæœªå®Œå…¨ä¿®å¤)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"è®¡ç®—ç»„åˆå›æ’¤æ—¶å‡ºç°é”™è¯¯: {e}\")\n",
    "# ç»˜åˆ¶ç»„åˆå›æ’¤æ›²çº¿\n",
    "portfolio_df = plot_portfolio_drawdown(merged_data, portfolio_weights)\n",
    "\n",
    "# ä¸å„å•é¡¹èµ„äº§å›æ’¤å¯¹æ¯”\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ç»„åˆä¸å„å•é¡¹èµ„äº§æœ€å¤§å›æ’¤å¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è®¡ç®—å¹¶æ˜¾ç¤ºå„å•é¡¹èµ„äº§çš„å›æ’¤\n",
    "individual_drawdowns = {}\n",
    "assets = ['é»„é‡‘', 'çŸ­è', 'é•¿å€º', 'è‚¡ç¥¨']\n",
    "\n",
    "print(f\"{'èµ„äº§':<10} {'æœ€å¤§å›æ’¤':<10} {'ä¿®å¤æ—¶é—´':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for asset in assets:\n",
    "    max_dd, _, _, _, recovery_months = calculate_max_drawdown_and_recovery(merged_data, asset)\n",
    "    individual_drawdowns[asset] = abs(max_dd)\n",
    "    recovery_text = f\"{recovery_months}ä¸ªæœˆ\" if recovery_months else \"æœªä¿®å¤\"\n",
    "    print(f\"{asset:<10} {max_dd*100:>9.2f}% {recovery_text:<10}\")\n",
    "\n",
    "# è®¡ç®—ç»„åˆå›æ’¤\n",
    "max_dd, peak_date, dd_date, recovery_date, recovery_months = calculate_portfolio_drawdown_and_recovery(merged_data, portfolio_weights)\n",
    "portfolio_max_dd = max_dd\n",
    "print(f\"{'ç»„åˆ':<10} {portfolio_max_dd*100:>9.2f}% {recovery_months if recovery_months else 'æœªä¿®å¤':<10}\")\n",
    "\n",
    "# è®¡ç®—é£é™©é™ä½æ•ˆæœ\n",
    "avg_individual_drawdown = np.mean(list(individual_drawdowns.values()))\n",
    "risk_reduction = (avg_individual_drawdown - abs(portfolio_max_dd)) / avg_individual_drawdown * 100\n",
    "\n",
    "print(f\"\\né£é™©åˆ†æ•£æ•ˆæœ:\")\n",
    "print(f\"  å„èµ„äº§å¹³å‡æœ€å¤§å›æ’¤: {avg_individual_drawdown*100:.2f}%\")\n",
    "print(f\"  ç»„åˆæœ€å¤§å›æ’¤: {abs(portfolio_max_dd)*100:.2f}%\")\n",
    "print(f\"  é£é™©é™ä½å¹…åº¦: {risk_reduction:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953059fe",
   "metadata": {},
   "source": [
    "# èåˆå›æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def _annualize_vol(returns: pd.Series, periods_per_year: int = 12) -> float:\n",
    "    \"\"\"è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡\"\"\"\n",
    "    return returns.std(ddof=1) * np.sqrt(periods_per_year)\n",
    "\n",
    "def inverse_vol_weights(vols: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"æ ¹æ®æ³¢åŠ¨ç‡è®¡ç®—é€†æ³¢åŠ¨ç‡æƒé‡\"\"\"\n",
    "    MIN_VOL = 0.001\n",
    "    vols_safe = np.maximum(vols, MIN_VOL)\n",
    "    inv = 1.0 / vols_safe\n",
    "    w = inv / np.sum(inv)\n",
    "    return w\n",
    "\n",
    "def compute_monthly_prices(prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"å°†æ—¥åº¦æ•°æ®è½¬æ¢ä¸ºæœˆåº¦æ•°æ®ï¼ˆå–æœˆæœ«ä»·æ ¼ï¼‰\"\"\"\n",
    "    df = prices.copy()\n",
    "    if 'date' in df.columns:\n",
    "        df = df.set_index(pd.to_datetime(df['date'])).drop(columns=['date'])\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError('prices must have a DatetimeIndex or a date column')\n",
    "    monthly = df.resample('ME').last()\n",
    "    return monthly\n",
    "\n",
    "def calculate_portfolio_contribution_vol(\n",
    "    returns: pd.DataFrame,\n",
    "    holdings: Dict[str, float],\n",
    "    prices: pd.Series,\n",
    "    assets: list\n",
    ") -> np.ndarray:\n",
    "    \"\"\"è®¡ç®—ç»„åˆä¸­å„èµ„äº§çš„é£é™©è´¡çŒ®ï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    total_value = sum(holdings[a] * prices[a] for a in assets)\n",
    "    if total_value <= 0:\n",
    "        return np.array([1/len(assets)] * len(assets))\n",
    "    \n",
    "    current_weights = np.array([holdings[a] * prices[a] / total_value for a in assets])\n",
    "    vols = np.array([_annualize_vol(returns[a].dropna()) for a in assets])\n",
    "    risk_contributions = current_weights * vols\n",
    "    \n",
    "    return risk_contributions\n",
    "\n",
    "def rebalance_portfolio(\n",
    "    holdings: Dict[str, float],\n",
    "    current_prices: pd.Series,\n",
    "    target_weights: Dict[str, float],\n",
    "    assets: List[str],\n",
    "    transaction_cost_rate: float = 0.001  # 0.1% äº¤æ˜“æˆæœ¬\n",
    ") -> Tuple[Dict[str, float], List[Dict], float]:\n",
    "    \"\"\"\n",
    "    æ‰§è¡Œç»„åˆå†å¹³è¡¡\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - holdings: å½“å‰æŒä»“ä»½é¢\n",
    "    - current_prices: å½“å‰ä»·æ ¼\n",
    "    - target_weights: ç›®æ ‡æƒé‡\n",
    "    - assets: èµ„äº§åˆ—è¡¨\n",
    "    - transaction_cost_rate: äº¤æ˜“æˆæœ¬ç‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    - è°ƒæ•´åçš„æŒä»“\n",
    "    - äº¤æ˜“è®°å½•åˆ—è¡¨\n",
    "    - æ€»äº¤æ˜“æˆæœ¬\n",
    "    \"\"\"\n",
    "    # è®¡ç®—å½“å‰å¸‚å€¼å’Œæƒé‡\n",
    "    current_values = {a: holdings[a] * current_prices[a] for a in assets}\n",
    "    total_value = sum(current_values.values())\n",
    "    current_weights = {a: current_values[a] / total_value for a in assets}\n",
    "    \n",
    "    # è®¡ç®—ç›®æ ‡å¸‚å€¼\n",
    "    target_values = {a: total_value * target_weights[a] for a in assets}\n",
    "    \n",
    "    # è®¡ç®—éœ€è¦è°ƒæ•´çš„é‡‘é¢\n",
    "    adjustments = {a: target_values[a] - current_values[a] for a in assets}\n",
    "    \n",
    "    # åˆ†ç¦»ä¹°å…¥å’Œå–å‡º\n",
    "    to_sell = {a: -adj for a, adj in adjustments.items() if adj < -0.01}  # å–å‡ºï¼ˆé‡‘é¢ä¸ºæ­£ï¼‰\n",
    "    to_buy = {a: adj for a, adj in adjustments.items() if adj > 0.01}    # ä¹°å…¥ï¼ˆé‡‘é¢ä¸ºæ­£ï¼‰\n",
    "    \n",
    "    transactions = []\n",
    "    total_transaction_cost = 0.0\n",
    "    new_holdings = holdings.copy()\n",
    "    \n",
    "    # å…ˆå–å‡ºè¶…é…èµ„äº§\n",
    "    cash_from_selling = 0.0\n",
    "    for asset, sell_value in to_sell.items():\n",
    "        sell_shares = sell_value / current_prices[asset]\n",
    "        transaction_cost = sell_value * transaction_cost_rate\n",
    "        cash_from_selling += sell_value - transaction_cost\n",
    "        \n",
    "        new_holdings[asset] -= sell_shares\n",
    "        total_transaction_cost += transaction_cost\n",
    "        \n",
    "        transactions.append({\n",
    "            'action': 'å–å‡º',\n",
    "            'asset': asset,\n",
    "            'amount': sell_value,\n",
    "            'shares': sell_shares,\n",
    "            'price': current_prices[asset],\n",
    "            'cost': transaction_cost\n",
    "        })\n",
    "    \n",
    "    # å†ä¹°å…¥ä½é…èµ„äº§\n",
    "    if len(to_buy) > 0 and cash_from_selling > 0:\n",
    "        # æŒ‰æ¯”ä¾‹åˆ†é…å¯ç”¨èµ„é‡‘\n",
    "        total_to_buy = sum(to_buy.values())\n",
    "        available_cash = cash_from_selling  # å–å‡ºæ‰€å¾—ç°é‡‘\n",
    "        \n",
    "        for asset, buy_value in to_buy.items():\n",
    "            # æŒ‰åŸå§‹éœ€æ±‚æ¯”ä¾‹åˆ†é…å¯ç”¨èµ„é‡‘\n",
    "            actual_buy_value = min(buy_value, available_cash * (buy_value / total_to_buy))\n",
    "            transaction_cost = actual_buy_value * transaction_cost_rate\n",
    "            net_buy_value = actual_buy_value - transaction_cost\n",
    "            buy_shares = net_buy_value / current_prices[asset]\n",
    "            \n",
    "            new_holdings[asset] += buy_shares\n",
    "            total_transaction_cost += transaction_cost\n",
    "            \n",
    "            transactions.append({\n",
    "                'action': 'ä¹°å…¥',\n",
    "                'asset': asset,\n",
    "                'amount': actual_buy_value,\n",
    "                'shares': buy_shares,\n",
    "                'price': current_prices[asset],\n",
    "                'cost': transaction_cost\n",
    "            })\n",
    "    \n",
    "    return new_holdings, transactions, total_transaction_cost\n",
    "\n",
    "def backtest_permanent_portfolio_v2(\n",
    "    start_year: int,\n",
    "    start_month: int,\n",
    "    price: float,\n",
    "    M: int,\n",
    "    cash_col: str = 'çŸ­è',\n",
    "    longbond_col: str = 'é•¿å€º',\n",
    "    gold_col: str = 'é»„é‡‘',\n",
    "    equity_col: str = 'è‚¡ç¥¨',\n",
    "    alpha: float = 0.0,  # é»˜è®¤çº¯æ°¸ä¹…ç»„åˆ\n",
    "    vol_lookback: int = 6,\n",
    "    initial_capital: float = 0.0,\n",
    "    use_portfolio_vol: bool = True,\n",
    "    rebalance_threshold: float = 0.1,  # åç¦»5%è§¦å‘è°ƒä»“\n",
    "    transaction_cost_rate: float = 0.001,  # 0.1%äº¤æ˜“æˆæœ¬\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    æ”¹è¿›çš„æ°¸ä¹…ç»„åˆå›æµ‹ï¼ˆå®Œæ•´è°ƒä»“ç‰ˆï¼‰\n",
    "    \n",
    "    æ ¸å¿ƒé€»è¾‘ï¼š\n",
    "    1. æ¯æ¬¡å®šæŠ•åï¼Œå…ˆç”¨æ–°é’±å°½é‡çº å\n",
    "    2. æ£€æŸ¥åç¦»åº¦ï¼Œè¶…è¿‡é˜ˆå€¼åˆ™å–å‡ºè¶…é…ã€ä¹°å…¥ä½é…\n",
    "    3. è€ƒè™‘äº¤æ˜“æˆæœ¬\n",
    "    \"\"\"\n",
    "    \n",
    "    df = get_data()\n",
    "    prices_monthly = compute_monthly_prices(df)\n",
    "    \n",
    "    start_ts = pd.Timestamp(start_year, start_month, 1)\n",
    "    if start_ts not in prices_monthly.index:\n",
    "        valid_dates = prices_monthly.index[prices_monthly.index >= start_ts]\n",
    "        if len(valid_dates) == 0:\n",
    "            raise ValueError(f\"æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ä» {start_year}-{start_month} å¼€å§‹å›æµ‹\")\n",
    "        start_ts = valid_dates[0]\n",
    "    \n",
    "    start_idx = prices_monthly.index.get_loc(start_ts)\n",
    "    \n",
    "    if start_idx + M > len(prices_monthly):\n",
    "        raise ValueError(f\"æ•°æ®ä¸è¶³ï¼šéœ€è¦ {M} ä¸ªæœˆï¼Œä½†åªæœ‰ {len(prices_monthly) - start_idx} ä¸ªæœˆå¯ç”¨\")\n",
    "    \n",
    "    assets = [cash_col, longbond_col, gold_col, equity_col]\n",
    "    risk_assets = [longbond_col, gold_col, equity_col]\n",
    "    holdings = {a: 0.0 for a in assets}\n",
    "    total_cost = 0.0\n",
    "    total_transaction_costs = 0.0\n",
    "    \n",
    "    monthly_records = []\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"æ°¸ä¹…ç»„åˆå›æµ‹ï¼ˆå®Œæ•´ç‰ˆï¼‰ï¼š{start_year}å¹´{start_month}æœˆ å¼€å§‹ï¼Œå®šæŠ• {M} ä¸ªæœˆ\")\n",
    "    print(f\"å‚æ•°ï¼šalpha={alpha}, è°ƒä»“é˜ˆå€¼={rebalance_threshold:.1%}, äº¤æ˜“æˆæœ¬={transaction_cost_rate:.2%}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # åˆå§‹å»ºä»“\n",
    "    if initial_capital > 0:\n",
    "        date_0 = prices_monthly.index[start_idx]\n",
    "        print(f\"ğŸ“ ç¬¬ 0 æœˆåˆå§‹å»ºä»“ ({date_0.date()})\")\n",
    "        print(f\"åˆå§‹èµ„é‡‘: {initial_capital:.2f}å…ƒ\\n\")\n",
    "        \n",
    "        target_weights = {a: 0.25 for a in assets}\n",
    "        \n",
    "        for asset in assets:\n",
    "            amount = initial_capital * target_weights[asset]\n",
    "            price_0 = prices_monthly.loc[date_0, asset]\n",
    "            shares = amount / price_0\n",
    "            holdings[asset] += shares\n",
    "            total_cost += amount\n",
    "            print(f\"  {asset}: æŠ•å…¥ {amount:.2f}å…ƒ, ä»·æ ¼ {price_0:.4f}, ä»½é¢ {shares:.4f}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # æœˆåº¦å®šæŠ•å¾ªç¯\n",
    "    for i in range(M):\n",
    "        month_idx = start_idx + i\n",
    "        date = prices_monthly.index[month_idx]\n",
    "        current_prices = prices_monthly.loc[date]\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ğŸ“… ç¬¬ {i+1} æœˆå®šæŠ• ({date.date()})\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # === æ­¥éª¤1ï¼šè®¡ç®—ç›®æ ‡æƒé‡ ===\n",
    "        lookback_start = max(0, month_idx - vol_lookback)\n",
    "        window_returns = prices_monthly.pct_change().iloc[lookback_start:month_idx+1].dropna(how='all')\n",
    "        \n",
    "        if alpha == 0:\n",
    "            # çº¯æ°¸ä¹…ç»„åˆï¼šå››èµ„äº§å„25%\n",
    "            target_weights = {a: 0.25 for a in assets}\n",
    "        elif alpha == 1:\n",
    "            # çº¯é£é™©å¹³ä»·\n",
    "            if use_portfolio_vol and i > 0 and window_returns.shape[0] >= 2:\n",
    "                risk_contribs = calculate_portfolio_contribution_vol(\n",
    "                    window_returns, holdings, current_prices, risk_assets\n",
    "                )\n",
    "                rp3 = inverse_vol_weights(risk_contribs)\n",
    "            else:\n",
    "                if window_returns.shape[0] < 2:\n",
    "                    vols = np.array([\n",
    "                        _annualize_vol(prices_monthly[longbond_col].pct_change().dropna()),\n",
    "                        _annualize_vol(prices_monthly[gold_col].pct_change().dropna()),\n",
    "                        _annualize_vol(prices_monthly[equity_col].pct_change().dropna()),\n",
    "                    ])\n",
    "                else:\n",
    "                    vols = np.array([\n",
    "                        _annualize_vol(window_returns[longbond_col].dropna()),\n",
    "                        _annualize_vol(window_returns[gold_col].dropna()),\n",
    "                        _annualize_vol(window_returns[equity_col].dropna()),\n",
    "                    ])\n",
    "                rp3 = inverse_vol_weights(vols)\n",
    "            \n",
    "            target_weights = {\n",
    "                cash_col: 0.25,\n",
    "                longbond_col: float(rp3[0] * 0.75),\n",
    "                gold_col: float(rp3[1] * 0.75),\n",
    "                equity_col: float(rp3[2] * 0.75)\n",
    "            }\n",
    "        else:\n",
    "            # æ··åˆç­–ç•¥\n",
    "            if use_portfolio_vol and i > 0 and window_returns.shape[0] >= 2:\n",
    "                risk_contribs = calculate_portfolio_contribution_vol(\n",
    "                    window_returns, holdings, current_prices, risk_assets\n",
    "                )\n",
    "                rp3 = inverse_vol_weights(risk_contribs)\n",
    "            else:\n",
    "                if window_returns.shape[0] < 2:\n",
    "                    vols = np.array([\n",
    "                        _annualize_vol(prices_monthly[longbond_col].pct_change().dropna()),\n",
    "                        _annualize_vol(prices_monthly[gold_col].pct_change().dropna()),\n",
    "                        _annualize_vol(prices_monthly[equity_col].pct_change().dropna()),\n",
    "                    ])\n",
    "                else:\n",
    "                    vols = np.array([\n",
    "                        _annualize_vol(window_returns[longbond_col].dropna()),\n",
    "                        _annualize_vol(window_returns[gold_col].dropna()),\n",
    "                        _annualize_vol(window_returns[equity_col].dropna()),\n",
    "                    ])\n",
    "                rp3 = inverse_vol_weights(vols)\n",
    "            \n",
    "            # æ··åˆï¼šæ°¸ä¹…ç»„åˆ(1/4) + é£é™©å¹³ä»·\n",
    "            pp4 = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "            rp4 = np.array([0.25, rp3[0]*0.75, rp3[1]*0.75, rp3[2]*0.75])\n",
    "            rp4 = rp4 / rp4.sum()\n",
    "            \n",
    "            blended = alpha * rp4 + (1 - alpha) * pp4\n",
    "            target_weights = {\n",
    "                cash_col: float(blended[0]),\n",
    "                longbond_col: float(blended[1]),\n",
    "                gold_col: float(blended[2]),\n",
    "                equity_col: float(blended[3])\n",
    "            }\n",
    "        \n",
    "        # === æ­¥éª¤2ï¼šè®¡ç®—å½“å‰çŠ¶æ€ ===\n",
    "        current_value = sum(holdings[a] * current_prices[a] for a in assets)\n",
    "        \n",
    "        if current_value > 0:\n",
    "            current_weights = {\n",
    "                a: holdings[a] * current_prices[a] / current_value \n",
    "                for a in assets\n",
    "            }\n",
    "            print(f\"\\nğŸ“Š å®šæŠ•å‰çŠ¶æ€:\")\n",
    "            print(f\"   æ€»å¸‚å€¼: {current_value:.2f}å…ƒ\")\n",
    "            print(f\"   å½“å‰æƒé‡: \", end=\"\")\n",
    "            for a in assets:\n",
    "                print(f\"{a}={current_weights[a]:.1%} \", end=\"\")\n",
    "            print()\n",
    "        else:\n",
    "            current_weights = {a: 0.25 for a in assets}\n",
    "        \n",
    "        print(f\"   ç›®æ ‡æƒé‡: \", end=\"\")\n",
    "        for a in assets:\n",
    "            print(f\"{a}={target_weights[a]:.1%} \", end=\"\")\n",
    "        print()\n",
    "        \n",
    "        # === æ­¥éª¤3ï¼šæ™ºèƒ½å®šæŠ•ï¼ˆç”¨æ–°é’±çº åï¼‰===\n",
    "        print(f\"\\nğŸ’° æœ¬æœˆå®šæŠ• {price:.2f}å…ƒ\")\n",
    "        \n",
    "        target_value_after = current_value + price\n",
    "        target_values = {a: target_value_after * target_weights[a] for a in assets}\n",
    "        current_values = {a: holdings[a] * current_prices[a] for a in assets}\n",
    "        gaps = {a: target_values[a] - current_values[a] for a in assets}\n",
    "        \n",
    "        # æ–°é’±ä¼˜å…ˆæŠ•å‘ç¼ºå£å¤§çš„èµ„äº§\n",
    "        to_invest = {a: gap for a, gap in gaps.items() if gap > 0}\n",
    "        total_gap = sum(to_invest.values())\n",
    "        \n",
    "        if total_gap > 0:\n",
    "            if total_gap <= price:\n",
    "                # æ–°é’±è¶³å¤Ÿå¡«è¡¥æ‰€æœ‰ç¼ºå£\n",
    "                for asset, gap in to_invest.items():\n",
    "                    shares = gap / current_prices[asset]\n",
    "                    holdings[asset] += shares\n",
    "                    print(f\"   {asset}: æŠ•å…¥ {gap:.2f}å…ƒ (å¡«è¡¥ç¼ºå£)\")\n",
    "                \n",
    "                # å‰©ä½™æŒ‰ç›®æ ‡æƒé‡åˆ†é…\n",
    "                remaining = price - total_gap\n",
    "                if remaining > 1:\n",
    "                    for asset in assets:\n",
    "                        amount = remaining * target_weights[asset]\n",
    "                        shares = amount / current_prices[asset]\n",
    "                        holdings[asset] += shares\n",
    "                        print(f\"   {asset}: æŠ•å…¥ {amount:.2f}å…ƒ (å‰©ä½™åˆ†é…)\")\n",
    "            else:\n",
    "                # æ–°é’±ä¸å¤Ÿï¼ŒæŒ‰æ¯”ä¾‹æŠ•å…¥\n",
    "                scale = price / total_gap\n",
    "                for asset, gap in to_invest.items():\n",
    "                    amount = gap * scale\n",
    "                    shares = amount / current_prices[asset]\n",
    "                    holdings[asset] += shares\n",
    "                    print(f\"   {asset}: æŠ•å…¥ {amount:.2f}å…ƒ (æŒ‰æ¯”ä¾‹ {scale:.1%})\")\n",
    "        else:\n",
    "            # æ‰€æœ‰èµ„äº§éƒ½è¶…é…ï¼ŒæŒ‰ç›®æ ‡æƒé‡æŠ•å…¥\n",
    "            for asset in assets:\n",
    "                amount = price * target_weights[asset]\n",
    "                shares = amount / current_prices[asset]\n",
    "                holdings[asset] += shares\n",
    "                print(f\"   {asset}: æŠ•å…¥ {amount:.2f}å…ƒ (æŒ‰æƒé‡)\")\n",
    "        \n",
    "        total_cost += price\n",
    "        \n",
    "        # === æ­¥éª¤4ï¼šæ£€æŸ¥å¹¶æ‰§è¡Œè°ƒä»“ ===\n",
    "        new_value = sum(holdings[a] * current_prices[a] for a in assets)\n",
    "        new_weights = {a: holdings[a] * current_prices[a] / new_value for a in assets}\n",
    "        \n",
    "        deviations = {a: abs(new_weights[a] - target_weights[a]) for a in assets}\n",
    "        max_deviation = max(deviations.values())\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ å®šæŠ•åçŠ¶æ€:\")\n",
    "        print(f\"   æ€»å¸‚å€¼: {new_value:.2f}å…ƒ\")\n",
    "        print(f\"   å®é™…æƒé‡: \", end=\"\")\n",
    "        for a in assets:\n",
    "            print(f\"{a}={new_weights[a]:.1%} \", end=\"\")\n",
    "        print()\n",
    "        print(f\"   æœ€å¤§åç¦»: {max_deviation:.2%}\")\n",
    "        \n",
    "        if max_deviation > rebalance_threshold:\n",
    "            print(f\"\\nâš–ï¸  è§¦å‘è°ƒä»“ï¼åç¦»è¶…è¿‡ {rebalance_threshold:.1%}\")\n",
    "            \n",
    "            holdings, transactions, txn_cost = rebalance_portfolio(\n",
    "                holdings, current_prices, target_weights, assets, transaction_cost_rate\n",
    "            )\n",
    "            \n",
    "            total_transaction_costs += txn_cost\n",
    "            \n",
    "            for txn in transactions:\n",
    "                print(f\"   {txn['action']} {txn['asset']}: \"\n",
    "                      f\"{txn['amount']:.2f}å…ƒ ({txn['shares']:.4f}ä»½), \"\n",
    "                      f\"æˆæœ¬ {txn['cost']:.2f}å…ƒ\")\n",
    "            \n",
    "            print(f\"   è°ƒä»“æ€»æˆæœ¬: {txn_cost:.2f}å…ƒ\")\n",
    "            \n",
    "            # é‡æ–°è®¡ç®—è°ƒä»“åçš„æƒé‡\n",
    "            final_value = sum(holdings[a] * current_prices[a] for a in assets)\n",
    "            final_weights = {a: holdings[a] * current_prices[a] / final_value for a in assets}\n",
    "            \n",
    "            print(f\"   è°ƒä»“åæƒé‡: \", end=\"\")\n",
    "            for a in assets:\n",
    "                print(f\"{a}={final_weights[a]:.1%} \", end=\"\")\n",
    "            print()\n",
    "        else:\n",
    "            final_value = new_value\n",
    "            final_weights = new_weights\n",
    "        \n",
    "        # === è®¡ç®—æ”¶ç›Š ===\n",
    "        total_profit = final_value - total_cost - total_transaction_costs\n",
    "        profit_rate = (total_profit / total_cost * 100) if total_cost > 0 else 0\n",
    "        \n",
    "        print(f\"\\nğŸ’¼ æœ¬æœˆæ€»ç»“:\")\n",
    "        print(f\"   ç´¯è®¡æŠ•å…¥: {total_cost:.2f}å…ƒ\")\n",
    "        print(f\"   ç´¯è®¡æˆæœ¬: {total_transaction_costs:.2f}å…ƒ\")\n",
    "        print(f\"   å½“å‰å¸‚å€¼: {final_value:.2f}å…ƒ\")\n",
    "        print(f\"   å‡€æ”¶ç›Š: {total_profit:.2f}å…ƒ ({profit_rate:+.2f}%)\")\n",
    "        print()\n",
    "        \n",
    "        monthly_records.append({\n",
    "            'month': i + 1,\n",
    "            'date': date,\n",
    "            'total_cost': total_cost,\n",
    "            'total_value': final_value,\n",
    "            'profit': total_profit,\n",
    "            'profit_rate': profit_rate,\n",
    "            'weights': final_weights.copy(),\n",
    "            'transaction_costs': total_transaction_costs\n",
    "        })\n",
    "    \n",
    "    # === æœ€ç»ˆæ€»ç»“ ===\n",
    "    final_record = monthly_records[-1]\n",
    "    years = M / 12\n",
    "    annualized_return = ((final_record['total_value'] / final_record['total_cost']) ** (1/years) - 1) * 100\n",
    "    \n",
    "    # è®¡ç®—æœ€å¤§å›æ’¤\n",
    "    nav_series = [r['total_value'] / r['total_cost'] for r in monthly_records]\n",
    "    peak = nav_series[0]\n",
    "    max_drawdown = 0\n",
    "    for nav in nav_series:\n",
    "        if nav > peak:\n",
    "            peak = nav\n",
    "        drawdown = (nav - peak) / peak\n",
    "        if drawdown < max_drawdown:\n",
    "            max_drawdown = drawdown\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“Š å›æµ‹æ€»ç»“\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"å®šæŠ•æ—¶é•¿: {M}ä¸ªæœˆ ({years:.2f}å¹´)\")\n",
    "    print(f\"æ€»æŠ•å…¥: {final_record['total_cost']:.2f}å…ƒ\")\n",
    "    print(f\"äº¤æ˜“æˆæœ¬: {total_transaction_costs:.2f}å…ƒ ({total_transaction_costs/final_record['total_cost']*100:.2f}%)\")\n",
    "    print(f\"æœ€ç»ˆå¸‚å€¼: {final_record['total_value']:.2f}å…ƒ\")\n",
    "    print(f\"å‡€æ”¶ç›Š: {final_record['profit']:.2f}å…ƒ\")\n",
    "    print(f\"ç´¯è®¡æ”¶ç›Šç‡: {final_record['profit_rate']:.2f}%\")\n",
    "    print(f\"å¹´åŒ–æ”¶ç›Šç‡: {annualized_return:.2f}%\")\n",
    "    print(f\"æœ€å¤§å›æ’¤: {max_drawdown*100:.2f}%\")\n",
    "    print(f\"\\næœ€ç»ˆæŒä»“:\")\n",
    "    for asset in assets:\n",
    "        value = holdings[asset] * prices_monthly.loc[monthly_records[-1]['date'], asset]\n",
    "        weight = value / final_record['total_value']\n",
    "        print(f\"  {asset}: {holdings[asset]:.4f}ä»½, å¸‚å€¼ {value:.2f}å…ƒ ({weight:.2%})\")\n",
    "    \n",
    "    return {\n",
    "        'annualized_return': annualized_return,\n",
    "        'total_return': final_record['profit_rate'],\n",
    "        'max_drawdown': max_drawdown * 100,\n",
    "        'total_cost': final_record['total_cost'],\n",
    "        'final_value': final_record['total_value'],\n",
    "        'transaction_costs': total_transaction_costs,\n",
    "        'monthly_records': monthly_records,\n",
    "        'holdings': holdings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc114aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ä»2018å¹´4æœˆå¼€å§‹ï¼Œæ¯æœˆå®šæŠ•10000å…ƒï¼Œå®šæŠ•72ä¸ªæœˆ\n",
    "    result = backtest_permanent_portfolio_v2(\n",
    "        start_year=2019,\n",
    "        start_month=1,\n",
    "        price=10000,\n",
    "        M=59,\n",
    "        alpha=0.3,  # é£é™©å¹³ä»·æƒé‡50%\n",
    "        vol_lookback=3,  # å›çœ‹12ä¸ªæœˆ\n",
    "        initial_capital=100000,  # åˆå§‹å»ºä»“10ä¸‡å…ƒ,\n",
    "        transaction_cost_rate=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e28c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
